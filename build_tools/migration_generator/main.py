"""
Migration Generator - Generates SQL migrations from schema definitions.

This module provides optimized migration generation with:
- Schema caching for repeated runs
- Template pre-compilation
- Efficient dialect handling
- Comprehensive type safety
"""

from __future__ import annotations

import argparse
import sys
from dataclasses import dataclass, field
from functools import lru_cache
from pathlib import Path
from typing import Any, Final, Iterator

from jinja2 import Environment, FileSystemLoader

# Add parent directory to path for shared imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from shared import (
    SchemaCache,
    SchemaError,
    SchemaValidationError,
    DialectError,
    load_schema,
)

# Default preset values for common SQL expressions
DEFAULT_PRESETS: Final[dict[str, dict[str, str]]] = {
    "now": {
        "sqlite": "(datetime('now'))",
        "postgres": "now()",
        "mysql": "CURRENT_TIMESTAMP",
    },
    "json_empty_object": {
        "sqlite": "'{}'",
        "postgres": "'{}'",
        "mysql": "'{}'",
    },
    "json_empty_array": {
        "sqlite": "'[]'",
        "postgres": "'[]'",
        "mysql": "'[]'",
    },
}

# Default type mappings for each dialect
DEFAULT_TYPES: Final[dict[str, dict[str, str]]] = {
    "uuid": {"sqlite": "TEXT", "postgres": "TEXT", "mysql": "CHAR(36)"},
    "string": {"sqlite": "TEXT", "postgres": "TEXT", "mysql": "VARCHAR(255)"},
    "text": {"sqlite": "TEXT", "postgres": "TEXT", "mysql": "TEXT"},
    "json_text": {"sqlite": "TEXT", "postgres": "TEXT", "mysql": "TEXT"},
    "bool_flag": {"sqlite": "INTEGER", "postgres": "INTEGER", "mysql": "TINYINT(1)"},
    "timestamp": {"sqlite": "TEXT", "postgres": "TIMESTAMP WITH TIME ZONE", "mysql": "TIMESTAMP"},
    "number": {"sqlite": "REAL", "postgres": "DOUBLE PRECISION", "mysql": "DOUBLE"},
    "integer": {"sqlite": "INTEGER", "postgres": "INTEGER", "mysql": "INT"},
    "bigint": {"sqlite": "INTEGER", "postgres": "BIGINT", "mysql": "BIGINT"},
    "smallint": {"sqlite": "INTEGER", "postgres": "SMALLINT", "mysql": "SMALLINT"},
    "float": {"sqlite": "REAL", "postgres": "REAL", "mysql": "FLOAT"},
    "double": {"sqlite": "REAL", "postgres": "DOUBLE PRECISION", "mysql": "DOUBLE"},
    "boolean": {"sqlite": "INTEGER", "postgres": "BOOLEAN", "mysql": "TINYINT(1)"},
    "blob": {"sqlite": "BLOB", "postgres": "BYTEA", "mysql": "BLOB"},
}

DEFAULT_HEADER: Final[str] = "-- Auto-generated by migration_generator. Do not modify."

DEFAULT_AUTO_INCREMENT: Final[dict[str, str]] = {
    "postgres": "GENERATED BY DEFAULT AS IDENTITY",
    "mysql": "AUTO_INCREMENT",
    "sqlite": "AUTOINCREMENT",
}

@dataclass(frozen=True, slots=True)
class DialectConfig:
    """Configuration for a SQL dialect."""
    name: str
    output_path: Path
    header: str | None
    footer: str | None
    statement_terminator: str = ";"


class MigrationGenerator:
    """Generates SQL migrations for multiple database dialects.
    
    Optimizations:
    - Template pre-compilation
    - Cached type and preset lookups
    - Efficient string building
    """
    
    __slots__ = (
        "schema",
        "base_dir",
        "types",
        "dialects",
        "presets",
        "_table_template",
        "_index_template",
        "_schema_path",
    )
    
    def __init__(
        self,
        schema: dict[str, Any],
        base_dir: Path,
        schema_path: str | None = None,
    ) -> None:
        self.schema = schema
        self.base_dir = base_dir
        self._schema_path = schema_path
        
        # Merge schema-provided types with built-in defaults
        schema_types = schema.get("types", {})
        self.types: dict[str, dict[str, str]] = {**DEFAULT_TYPES, **schema_types}
        
        # Merge presets
        schema_presets = schema.get("presets", {})
        self.presets: dict[str, dict[str, str]] = {**DEFAULT_PRESETS, **schema_presets}
        
        self.dialects: dict[str, DialectConfig] = {}

        # Initialize Jinja environment with optimizations
        templates_dir = Path(__file__).parent / "templates"
        jinja_env = Environment(
            loader=FileSystemLoader(templates_dir),
            auto_reload=False,  # Disable auto-reload for performance
        )
        
        # Pre-compile templates
        self._table_template = jinja_env.get_template("table.sql.jinja")
        self._index_template = jinja_env.get_template("index.sql.jinja")

        if "dialects" not in schema:
            raise SchemaValidationError(
                "schema must define top-level 'dialects' mapping",
                schema_path,
            )

        for dialect_name, cfg in schema["dialects"].items():
            output = cfg.get("output")
            if not output:
                raise DialectError(
                    "requires an 'output' path",
                    dialect_name,
                    schema_path,
                )
            
            self.dialects[dialect_name] = DialectConfig(
                name=dialect_name,
                output_path=(self.base_dir / output).resolve(),
                header=DEFAULT_HEADER,
                footer=cfg.get("footer"),
                statement_terminator=cfg.get("statement_terminator", ";"),
            )

        if "tables" not in schema:
            raise SchemaValidationError(
                "schema must define a 'tables' list",
                schema_path,
            )

    def generate(self, dialect_name: str) -> str:
        """Generate SQL migration for a specific dialect.
        
        Args:
            dialect_name: Name of the target dialect.
            
        Returns:
            The complete SQL migration content.
            
        Raises:
            DialectError: If the dialect is not defined.
        """
        if dialect_name not in self.dialects:
            raise DialectError(
                "is not defined in schema",
                dialect_name,
                self._schema_path,
            )

        dialect_cfg = self.dialects[dialect_name]
        sections: list[str] = []

        # Header
        header = dialect_cfg.header or self.schema.get("default_header")
        if header:
            sections.append(header.strip())

        # Global prefix statements
        global_prefix = self.schema.get("global_statements", {}).get(dialect_name, {}).get("before_tables")
        if global_prefix:
            sections.append(self._join_statements(global_prefix))

        # Process tables
        for table in self.schema["tables"]:
            include = table.get("dialects")
            if include and dialect_name not in include:
                continue
            
            sections.append(self._render_table(table, dialect_name, dialect_cfg.statement_terminator))

            # Table extras
            table_extra = table.get("dialect_extras", {}).get(dialect_name)
            if table_extra:
                sections.append(self._join_statements(table_extra))

            # Indexes
            index_statements = list(self._render_indexes(table, dialect_name, dialect_cfg.statement_terminator))
            if index_statements:
                sections.append("\n".join(index_statements))

            # Dialect-specific indexes
            dial_indexes = table.get("dialect_indexes", {}).get(dialect_name, [])
            if dial_indexes:
                sections.append(self._join_statements(dial_indexes))

        # Global suffix statements
        global_suffix = self.schema.get("global_statements", {}).get(dialect_name, {}).get("after_tables")
        if global_suffix:
            sections.append(self._join_statements(global_suffix))

        # Footer
        footer = dialect_cfg.footer or self.schema.get("default_footer")
        if footer:
            sections.append(footer.strip())

        return "\n\n".join(s for s in sections if s.strip()) + "\n"

    def _render_indexes(
        self,
        table: dict[str, Any],
        dialect_name: str,
        terminator: str,
    ) -> Iterator[str]:
        """Render all indexes for a table as a generator."""
        for index in table.get("indexes", []):
            stmt = self._render_index(table, index, dialect_name, terminator)
            if stmt:
                yield stmt

    def write(self, dialect_name: str) -> Path:
        """Write migration to file for a specific dialect.
        
        Args:
            dialect_name: Name of the target dialect.
            
        Returns:
            Path to the written file.
        """
        dialect_cfg = self.dialects[dialect_name]
        content = self.generate(dialect_name)
        dialect_cfg.output_path.parent.mkdir(parents=True, exist_ok=True)
        dialect_cfg.output_path.write_text(content, encoding="utf-8")
        return dialect_cfg.output_path

    def _join_statements(self, statements: Iterator[Any] | list[Any]) -> str:
        """Join SQL statements with proper formatting."""
        rendered: list[str] = []
        for statement in statements:
            if statement is None:
                continue
            if isinstance(statement, str):
                rendered.append(statement.strip())
            elif isinstance(statement, dict):
                inline = statement.get("statement")
                if inline:
                    rendered.append(inline.strip())
            else:
                raise TypeError(f"Unsupported statement type: {type(statement)}")
        return "\n\n".join(rendered)

    def _render_table(
        self,
        table: dict[str, Any],
        dialect_name: str,
        terminator: str,
    ) -> str:
        """Render a CREATE TABLE statement."""
        name = table["name"]
        columns = table.get("columns", [])
        lines: list[str] = []
        table_pk = table.get("primary_key")
        if isinstance(table_pk, str):
            table_pk = [table_pk]

        for column in columns:
            col_line = self._render_column(column, table_pk, dialect_name)
            if col_line:
                lines.append(col_line)

        for constraint in table.get("constraints", []):
            rendered_constraint = self._render_constraint(constraint, dialect_name)
            if rendered_constraint:
                lines.append(rendered_constraint)

        composite_pk = table_pk if table_pk and len(table_pk) > 1 else None
        table_suffix = table.get("table_suffix", {}).get(dialect_name)

        return self._table_template.render(
            table={
                "name": name,
                "lines": lines,
                "composite_pk": composite_pk,
                "table_suffix": table_suffix,
            },
            terminator=terminator,
        )

    def _render_constraint(
        self,
        constraint: Any,
        dialect_name: str,
    ) -> str | None:
        """Render a table constraint."""
        if isinstance(constraint, str):
            return f"  {constraint.strip()}"
        
        if isinstance(constraint, dict):
            allowed_dialects = constraint.get("dialects")
            if allowed_dialects and dialect_name not in allowed_dialects:
                return None

            if "text" in constraint:
                return f"  {constraint['text'].strip()}"

            dialect_text = constraint.get("dialect_text", {}).get(dialect_name)
            if dialect_text:
                return f"  {dialect_text.strip()}"

        return None

    def _render_column(
        self,
        column: dict[str, Any],
        table_pk: list[str] | None,
        dialect_name: str,
    ) -> str | None:
        """Render a column definition."""
        include = column.get("dialects")
        if include and dialect_name not in include:
            return None

        name = column["name"]
        col_type = self._resolve_column_type(column, dialect_name)
        parts: list[str] = [f"  {name} {col_type}"]

        # Column modifiers
        default_val = self._resolve_default(column, dialect_name)
        nullable = column.get("nullable", True)
        unique = column.get("unique", False)
        is_pk = column.get("primary_key", False)
        references = column.get("references")
        on_delete = column.get("on_delete")
        on_update = column.get("on_update")
        check_expr = self._resolve_check(column, dialect_name)
        
        # Handle auto_increment
        auto_increment = column.get("auto_increment", False)
        apply_auto_increment = (
            bool(auto_increment.get(dialect_name))
            if isinstance(auto_increment, dict)
            else bool(auto_increment)
        )

        if not nullable:
            parts.append("NOT NULL")

        if default_val is not None:
            parts.append(f"DEFAULT {default_val}")

        if unique:
            parts.append("UNIQUE")

        # Only inline the primary key when it's not part of an explicit composite key
        if is_pk and not (table_pk and len(table_pk) > 1):
            parts.append("PRIMARY KEY")

        if apply_auto_increment:
            incr = self._auto_increment_keyword(dialect_name)
            if incr:
                parts.append(incr)

        if references:
            ref_text = self._resolve_reference(references, dialect_name)
            parts.append(f"REFERENCES {ref_text}")
            if on_delete:
                parts.append(f"ON DELETE {on_delete}")
            if on_update:
                parts.append(f"ON UPDATE {on_update}")

        if check_expr:
            parts.append(f"CHECK ({check_expr})")

        column_suffix = column.get("suffix", {}).get(dialect_name)
        if column_suffix:
            parts.append(column_suffix.strip())

        return " ".join(parts)

    def _render_index(
        self,
        table: dict[str, Any],
        index: dict[str, Any],
        dialect_name: str,
        terminator: str,
    ) -> str | None:
        """Render a CREATE INDEX statement."""
        include = index.get("dialects")
        if include and dialect_name not in include:
            return None

        # Generate index name if not provided
        name = index.get("name")
        if not name:
            cols = index.get("columns", [])
            name = f"idx_{table['name']}_{'_'.join(cols)}"

        # Handle IF NOT EXISTS logic
        has_explicit_if_not_exists = "if_not_exists" in index
        if_not_exists_raw = index.get("if_not_exists", True)
        
        if isinstance(if_not_exists_raw, dict):
            if_not_exists = bool(if_not_exists_raw.get(dialect_name, True))
        elif dialect_name == "mysql" and not has_explicit_if_not_exists:
            if_not_exists = False
        else:
            if_not_exists = bool(if_not_exists_raw)
        
        unique = index.get("unique", False)
        columns = index.get("columns")
        expression = index.get("expression")

        # Determine index body
        if expression:
            if isinstance(expression, str):
                body = expression
            elif isinstance(expression, dict):
                body = expression.get(dialect_name)
                if not body:
                    return None
            else:
                raise TypeError(f"Unsupported expression type for index '{name}': {type(expression)}")
        elif not columns:
            raise SchemaValidationError(
                f"index '{name}' must define 'columns' or 'expression'",
                self._schema_path,
            )
        else:
            body = f"{table['name']}({', '.join(columns)})"

        return self._index_template.render(
            index={
                "unique": unique,
                "if_not_exists": if_not_exists,
                "name": name,
                "body": body,
            },
            terminator=terminator,
        )

    def _resolve_column_type(
        self,
        column: dict[str, Any],
        dialect_name: str,
    ) -> str:
        """Resolve the SQL type for a column."""
        overrides = column.get("dialect_type")
        if overrides and dialect_name in overrides:
            return overrides[dialect_name]

        type_name = column.get("type")
        col_name = column.get("name", "<unknown>")
        
        if not type_name:
            raise SchemaValidationError(
                "column is missing required 'type'",
                self._schema_path,
                field=col_name,
            )

        if isinstance(type_name, dict):
            if dialect_name in type_name:
                return type_name[dialect_name]
            raise DialectError(
                f"column '{col_name}' type dict missing key",
                dialect_name,
                self._schema_path,
            )

        if type_name not in self.types:
            raise SchemaValidationError(
                f"type '{type_name}' not defined in schema types mapping",
                self._schema_path,
                field=col_name,
            )

        mapping = self.types[type_name]
        if dialect_name not in mapping:
            raise DialectError(
                f"type '{type_name}' missing mapping",
                dialect_name,
                self._schema_path,
            )

        return mapping[dialect_name]

    def _resolve_default(
        self,
        column: dict[str, Any],
        dialect_name: str,
    ) -> str | None:
        """Resolve the default value for a column."""
        default = column.get("default")
        if default is None:
            return None

        if isinstance(default, dict):
            if "preset" in default:
                return self._resolve_preset(default["preset"], dialect_name)
            return default.get(dialect_name)

        if isinstance(default, bool):
            return "1" if default else "0"

        if isinstance(default, (int, float)):
            return str(default)

        if isinstance(default, str) and default in self.presets:
            return self._resolve_preset(default, dialect_name)

        return str(default)

    def _resolve_check(
        self,
        column: dict[str, Any],
        dialect_name: str,
    ) -> str | None:
        """Resolve CHECK constraint expression."""
        check_expr = column.get("check")
        if check_expr is None:
            return None
        if isinstance(check_expr, dict):
            return check_expr.get(dialect_name)
        return str(check_expr)

    def _resolve_reference(
        self,
        reference: Any,
        dialect_name: str,
    ) -> str:
        """Resolve REFERENCES clause."""
        if isinstance(reference, str):
            return reference
        if isinstance(reference, dict):
            if "table" not in reference:
                raise SchemaValidationError(
                    "reference dict requires 'table'",
                    self._schema_path,
                )
            column = reference.get("column", "id")
            return f"{reference['table']}({column})"
        raise TypeError("unsupported reference value")

    @staticmethod
    def _auto_increment_keyword(dialect_name: str) -> str | None:
        """Get the auto-increment keyword for a dialect."""
        return DEFAULT_AUTO_INCREMENT.get(dialect_name)

    def _resolve_preset(self, preset_name: str, dialect_name: str) -> str:
        """Resolve a preset value for a dialect."""
        preset = self.presets.get(preset_name)
        if not preset:
            raise SchemaValidationError(
                f"Unknown default preset '{preset_name}'",
                self._schema_path,
            )
        value = preset.get(dialect_name)
        if value is None:
            raise DialectError(
                f"Preset '{preset_name}' missing value",
                dialect_name,
                self._schema_path,
            )
        return value


def generate_migrations(
    schema_path: Path,
    dialect: str | None = None,
) -> list[Path]:
    """Generate SQL migrations from a schema file.
    
    Args:
        schema_path: Path to the schema YAML file.
        dialect: Optional specific dialect to generate.
        
    Returns:
        List of paths to generated migration files.
    """
    schema = load_schema(schema_path)
    generator = MigrationGenerator(
        schema,
        base_dir=schema_path.parent,
        schema_path=str(schema_path),
    )
    
    output_paths: list[Path] = []
    
    dialects = [dialect] if dialect else list(generator.dialects.keys())
    for dialect_name in dialects:
        output_paths.append(generator.write(dialect_name))
    
    return output_paths


def main(argv: list[str] | None = None) -> None:
    """CLI entry point."""
    parser = argparse.ArgumentParser(
        description="Generate SQL migrations from schema description"
    )
    parser.add_argument("schema", type=Path, help="Path to schema YAML file")
    parser.add_argument(
        "--dialect",
        dest="dialect",
        type=str,
        help="Only generate a specific dialect (default: all dialects)",
    )

    args = parser.parse_args(argv)
    
    try:
        schema_path: Path = args.schema.resolve()
        output_paths = generate_migrations(schema_path, args.dialect)
        
        for path in output_paths:
            dialect = path.parent.name.replace("migrations_", "")
            print(f"Generated {dialect} migration at {path}")
    except (SchemaError, FileNotFoundError) as e:
        raise SystemExit(f"Error: {e}") from e


if __name__ == "__main__":
    main()
